{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/Users/sunnyyou/Programs/Real_Time_HAI/HIECNN/IMERG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58112\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GIS_ID</th>\n",
       "      <th>VMAX</th>\n",
       "      <th>VMAX_N06</th>\n",
       "      <th>VMAX_N12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL_200001_TD_2000060806</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL_200001_TD_2000060812</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL_200002_TD_2000062312</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL_200002_TD_2000062318</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL_200002_TD_2000062400</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GIS_ID  VMAX  VMAX_N06  VMAX_N12\n",
       "0  ATL_200001_TD_2000060806    25        25        25\n",
       "1  ATL_200001_TD_2000060812    25        25        25\n",
       "2  ATL_200002_TD_2000062312    30        30        25\n",
       "3  ATL_200002_TD_2000062318    30        30        30\n",
       "4  ATL_200002_TD_2000062400    30        30        30"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"DEV/ALL_TRAIN_DATA_RESAMPLE.csv\")\n",
    "train = train[[\"GIS_ID\", \"VMAX\", \"VMAX_N06\", \"VMAX_N12\"]]\n",
    "print(len(train.GIS_ID))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4312\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GIS_ID</th>\n",
       "      <th>VMAX</th>\n",
       "      <th>VMAX_N06</th>\n",
       "      <th>VMAX_N12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL_201801_TS_2018052812</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL_201801_TS_2018052818</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL_201801_TD_2018052900</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL_201801_TD_2018052906</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL_201801_TD_2018052912</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GIS_ID  VMAX  VMAX_N06  VMAX_N12\n",
       "0  ATL_201801_TS_2018052812    50        55        55\n",
       "1  ATL_201801_TS_2018052818    45        50        55\n",
       "2  ATL_201801_TD_2018052900    30        45        50\n",
       "3  ATL_201801_TD_2018052906    30        30        45\n",
       "4  ATL_201801_TD_2018052912    30        30        30"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"DEV/ALL_TEST_DATA.csv\")\n",
    "test = test[[\"GIS_ID\", \"VMAX\", \"VMAX_N06\", \"VMAX_N12\"]]\n",
    "print(len(test.GIS_ID))\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        0         1         2         3         4         5    6         7    \\\n",
      "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "2  0.000000  0.000000  0.002614  0.035389  0.031253  0.003356  0.0  0.000000   \n",
      "3  0.053374  0.086443  0.075739  0.183154  0.187500  0.022317  0.0  0.046795   \n",
      "4  0.312158  0.434224  0.340077  0.413843  0.241398  0.028628  0.0  0.202615   \n",
      "\n",
      "        8         9    ...       111       112       113  114  115  116  117  \\\n",
      "0  0.000000  0.000000  ...  0.327364  0.000000  0.000000  0.0  0.0  0.0  0.0   \n",
      "1  0.000000  0.000000  ...  0.000000  0.000000  0.022034  0.0  0.0  0.0  0.0   \n",
      "2  0.000000  0.000000  ...  0.000000  0.000000  0.022034  0.0  0.0  0.0  0.0   \n",
      "3  0.354221  0.840079  ...  0.000000  0.295887  0.192012  0.0  0.0  0.0  0.0   \n",
      "4  1.544581  4.629189  ...  0.100727  0.147943  0.047216  0.0  0.0  0.0  0.0   \n",
      "\n",
      "   118  119  120  \n",
      "0  0.0  0.0  0.0  \n",
      "1  0.0  0.0  0.0  \n",
      "2  0.0  0.0  0.0  \n",
      "3  0.0  0.0  0.0  \n",
      "4  0.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 121 columns]\n",
      "[25 25]\n"
     ]
    }
   ],
   "source": [
    "a = pd.read_csv(\"IMERG_CSV/\" + train.GIS_ID[0] + '.csv', header = None)\n",
    "print(a.head())\n",
    "pvmax = np.array([train.VMAX_N06[0], train.VMAX_N12[0]])\n",
    "print(pvmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img = []\n",
    "train_vmax = []\n",
    "train_label = []\n",
    "test_img = []\n",
    "test_vmax = []\n",
    "test_label = []\n",
    "for f in range(len(train.GIS_ID)) :\n",
    "    filename = f\"IMERG_CSV/{train.GIS_ID[f]}.csv\"\n",
    "    try:\n",
    "        temp = pd.read_csv(filename, header = None)\n",
    "        if (temp.shape != (121,121)):\n",
    "            continue\n",
    "        temp = temp[40:81]\n",
    "        temp = temp.iloc[:, 40:81]\n",
    "        temp = np.array(temp)\n",
    "        train_img.append(temp)\n",
    "        lab = train.VMAX[f]\n",
    "        train_label.append(lab)\n",
    "        pvmax = np.array([train.VMAX_N06[f], train.VMAX_N12[f]])\n",
    "        train_vmax.append(pvmax)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "\n",
    "for f in range(len(test.GIS_ID)) :\n",
    "    filename = f\"IMERG_CSV/{test.GIS_ID[f]}.csv\"\n",
    "    try:\n",
    "        temp = pd.read_csv(filename, header = None)\n",
    "        if (temp.shape != (121,121)):\n",
    "            continue\n",
    "        temp = temp[40:81]\n",
    "        temp = temp.iloc[:, 40:81]\n",
    "        temp = np.array(temp)\n",
    "        test_img.append(temp)\n",
    "        lab = test.VMAX[f]\n",
    "        test_label.append(lab)\n",
    "        pvmax = np.array([test.VMAX_N06[f], test.VMAX_N12[f]])\n",
    "        test_vmax.append(pvmax)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58112\n",
      "58112\n",
      "58112\n",
      "4312\n",
      "4312\n",
      "4312\n"
     ]
    }
   ],
   "source": [
    "print(len(train_img))\n",
    "print(len(train_vmax))\n",
    "print(len(train_label))\n",
    "print(len(test_img))\n",
    "print(len(test_vmax))\n",
    "print(len(test_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img = train_img\n",
    "X_train_vmax = train_vmax\n",
    "y_train = train_label\n",
    "X_test_img = test_img\n",
    "X_test_vmax = test_vmax\n",
    "y_test = test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_img = np.array(X_train_img)\n",
    "X_train_img = X_train_img.reshape(-1,41,41,1)\n",
    "X_train_img = X_train_img.astype('float32')\n",
    "X_train_vmax = np.array(X_train_vmax)\n",
    "X_train_vmax = X_train_vmax.reshape(-1,2)\n",
    "y_train = np.array(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_img = np.array(X_test_img)\n",
    "X_test_img = X_test_img.reshape(-1,41,41,1)\n",
    "X_test_img = X_test_img.astype('float32')\n",
    "X_test_vmax = np.array(X_test_vmax)\n",
    "X_test_vmax = X_test_vmax.reshape(-1,2)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " img_layer (InputLayer)      [(None, 61, 61, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (None, 50, 50, 64)           9280      ['img_layer[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (None, 39, 39, 64)           589888    ['conv2d[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (None, 38, 38, 64)           16448     ['conv2d_1[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 38, 38, 64)           256       ['conv2d_2[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2  (None, 19, 19, 64)           0         ['batch_normalization[0][0]'] \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (None, 11, 11, 64)           331840    ['max_pooling2d[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (None, 3, 3, 64)             331840    ['conv2d_3[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (None, 2, 2, 256)            65792     ['conv2d_4[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (None, 2, 2, 256)            1024      ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " flatten (Flatten)           (None, 1024)                 0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " vmax_layer (InputLayer)     [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (None, 1026)                 0         ['flatten[0][0]',             \n",
      "                                                                     'vmax_layer[0][0]']          \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, 256)                  262912    ['concatenate[0][0]']         \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, 170)                  43690     ['dense[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1652970 (6.31 MB)\n",
      "Trainable params: 1652330 (6.30 MB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " img_layer (InputLayer)      [(None, 61, 61, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (None, 50, 50, 256)          37120     ['img_layer[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (None, 50, 50, 256)          1024      ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPoolin  (None, 25, 25, 256)          0         ['batch_normalization_2[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (None, 24, 24, 128)          131200    ['max_pooling2d_1[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (None, 18, 18, 128)          802944    ['conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (None, 18, 18, 128)          512       ['conv2d_8[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPoolin  (None, 9, 9, 128)            0         ['batch_normalization_3[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (None, 8, 8, 64)             32832     ['max_pooling2d_2[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (None, 5, 5, 64)             65600     ['conv2d_9[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (None, 5, 5, 64)             256       ['conv2d_10[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPoolin  (None, 2, 2, 64)             0         ['batch_normalization_4[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)         (None, 256)                  0         ['max_pooling2d_3[0][0]']     \n",
      "                                                                                                  \n",
      " vmax_layer (InputLayer)     [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 258)                  0         ['flatten_1[0][0]',           \n",
      " )                                                                   'vmax_layer[0][0]']          \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 170)                  44030     ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1115518 (4.26 MB)\n",
      "Trainable params: 1114622 (4.25 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " img_layer (InputLayer)      [(None, 61, 61, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (None, 52, 58, 256)          10496     ['img_layer[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (None, 49, 49, 256)          2621696   ['conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (None, 49, 49, 256)          1024      ['conv2d_12[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPoolin  (None, 24, 24, 256)          0         ['batch_normalization_5[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (None, 19, 19, 128)          1179776   ['max_pooling2d_4[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (None, 19, 19, 128)          512       ['conv2d_13[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPoolin  (None, 9, 9, 128)            0         ['batch_normalization_6[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (None, 6, 6, 64)             131136    ['max_pooling2d_5[0][0]']     \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (None, 6, 6, 64)             256       ['conv2d_14[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPoolin  (None, 3, 3, 64)             0         ['batch_normalization_7[0][0]'\n",
      " g2D)                                                               ]                             \n",
      "                                                                                                  \n",
      " flatten_2 (Flatten)         (None, 576)                  0         ['max_pooling2d_6[0][0]']     \n",
      "                                                                                                  \n",
      " vmax_layer (InputLayer)     [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (None, 578)                  0         ['flatten_2[0][0]',           \n",
      " )                                                                   'vmax_layer[0][0]']          \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 170)                  98430     ['concatenate_2[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4043326 (15.42 MB)\n",
      "Trainable params: 4042430 (15.42 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 300km\n",
    "vmax_input = keras.Input(shape =(2,), name = \"vmax_layer\")\n",
    "img_input = keras.Input(shape =(61, 61, 1), name = \"img_layer\")\n",
    "\n",
    "w = keras.layers.Conv2D(64,12) (img_input)\n",
    "w = keras.layers.Conv2D(64,12)(w)\n",
    "w = keras.layers.Conv2D(64,2)(w)\n",
    "w = keras.layers.BatchNormalization()(w)\n",
    "w = keras.activations.linear(w)\n",
    "w = keras.layers.MaxPool2D(2,2)(w)\n",
    "w = keras.layers.Conv2D(64, 9)(w)\n",
    "w = keras.layers.Conv2D(64, 9)(w)\n",
    "w = keras.layers.Conv2D(256,2)(w)\n",
    "w = keras.layers.BatchNormalization()(w)\n",
    "img_output1 = keras.layers.Flatten()(w)\n",
    "\n",
    "merged_model1 = keras.layers.concatenate([img_output1, vmax_input])\n",
    "output_layer1 = keras.layers.Dense(256)(merged_model1)\n",
    "output_layer1 = keras.layers.Dense(170, activation = 'linear')(output_layer1)\n",
    "\n",
    "new_model1 = keras.Model(inputs = [img_input, vmax_input], outputs = output_layer1, name = \"model_1\")\n",
    "\n",
    "new_model1.summary()\n",
    "\n",
    "x = keras.layers.Conv2D(256, 12) (img_input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.activations.linear(x)\n",
    "x = keras.layers.MaxPool2D(2,2)(x)\n",
    "x = keras.layers.Conv2D(128,2, activation = 'linear')(x)\n",
    "x = keras.layers.Conv2D(128,7)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.activations.linear(x)\n",
    "x = keras.layers.MaxPool2D(2,2)(x)\n",
    "x = keras.layers.Conv2D(64,2, activation = 'linear')(x)\n",
    "x = keras.layers.Conv2D(64,4)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.activations.linear(x)\n",
    "x = keras.layers.MaxPool2D(2,2)(x)\n",
    "img_output2 = keras.layers.Flatten()(x)\n",
    "\n",
    "merged_model2 = keras.layers.concatenate([img_output2, vmax_input])\n",
    "output_layer2 = keras.layers.Dense(170, activation = 'linear')(merged_model2)\n",
    "\n",
    "new_model2 = keras.Model(inputs = [img_input, vmax_input], outputs = output_layer2, name = \"model_2\")\n",
    "\n",
    "new_model2.summary()\n",
    "\n",
    "y = keras.layers.Conv2D(256, (10,4))(img_input)\n",
    "y = keras.layers.Conv2D(256, (4,10))(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "y = keras.activations.linear(y)\n",
    "y = keras.layers.MaxPool2D(2,2)(y)\n",
    "y = keras.layers.Conv2D(128,6)(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "y = keras.activations.linear(y)\n",
    "y = keras.layers.MaxPool2D(2,2)(y)\n",
    "y = keras.layers.Conv2D(64,4)(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "y = keras.activations.linear(y)\n",
    "y = keras.layers.MaxPool2D(2,2)(y)\n",
    "img_output3 = keras.layers.Flatten()(y)\n",
    "\n",
    "merged_model3 = keras.layers.concatenate([img_output3, vmax_input])\n",
    "output_layer3 = keras.layers.Dense(170, activation = 'linear')(merged_model3)\n",
    "\n",
    "new_model3 = keras.Model(inputs = [img_input, vmax_input], outputs = output_layer3, name = \"model_3\")\n",
    "\n",
    "new_model3.summary()\n",
    "\n",
    "# z = keras.layers.Conv2D(256, 10)(img_input)\n",
    "# z = keras.layers.MaxPool2D(2,2)(z)\n",
    "# img_output4 = keras.layers.Flatten()(z)\n",
    "\n",
    "# merged_model4 = keras.layers.concatenate([img_output4, vmax_input])\n",
    "# output_layer4 = keras.layers.Dense(1, activation = 'sigmoid')(merged_model4)\n",
    "\n",
    "# new_model4 = keras.Model(inputs = [img_input, vmax_input], outputs = output_layer4, name = \"model_4\")\n",
    "\n",
    "# new_model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " img_layer (InputLayer)      [(None, 41, 41, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (None, 34, 34, 64)           4160      ['img_layer[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (None, 27, 27, 64)           262208    ['conv2d_15[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (None, 27, 27, 64)           4160      ['conv2d_16[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (None, 27, 27, 64)           256       ['conv2d_17[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.nn.relu (TFOpLambda)     (None, 27, 27, 64)           0         ['batch_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " max_pooling2d_7 (MaxPoolin  (None, 13, 13, 64)           0         ['tf.nn.relu[0][0]']          \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (None, 11, 11, 64)           36928     ['max_pooling2d_7[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (None, 9, 9, 64)             36928     ['conv2d_18[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (None, 9, 9, 256)            16640     ['conv2d_19[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (None, 9, 9, 256)            1024      ['conv2d_20[0][0]']           \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " flatten_3 (Flatten)         (None, 20736)                0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " vmax_layer (InputLayer)     [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (None, 20738)                0         ['flatten_3[0][0]',           \n",
      " )                                                                   'vmax_layer[0][0]']          \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 256)                  5309184   ['concatenate_3[0][0]']       \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 170)                  43690     ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5715178 (21.80 MB)\n",
      "Trainable params: 5714538 (21.80 MB)\n",
      "Non-trainable params: 640 (2.50 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " img_layer (InputLayer)      [(None, 41, 41, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (None, 34, 34, 256)          16640     ['img_layer[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (None, 34, 34, 256)          1024      ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.relu_1 (TFOpLambda)   (None, 34, 34, 256)          0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPoolin  (None, 17, 17, 256)          0         ['tf.nn.relu_1[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (None, 17, 17, 128)          32896     ['max_pooling2d_8[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (None, 13, 13, 128)          409728    ['conv2d_22[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (None, 13, 13, 128)          512       ['conv2d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.relu_2 (TFOpLambda)   (None, 13, 13, 128)          0         ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPoolin  (None, 6, 6, 128)            0         ['tf.nn.relu_2[0][0]']        \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (None, 6, 6, 64)             8256      ['max_pooling2d_9[0][0]']     \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (None, 4, 4, 64)             36928     ['conv2d_24[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (None, 4, 4, 64)             256       ['conv2d_25[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.relu_3 (TFOpLambda)   (None, 4, 4, 64)             0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooli  (None, 2, 2, 64)             0         ['tf.nn.relu_3[0][0]']        \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " flatten_4 (Flatten)         (None, 256)                  0         ['max_pooling2d_10[0][0]']    \n",
      "                                                                                                  \n",
      " vmax_layer (InputLayer)     [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (None, 258)                  0         ['flatten_4[0][0]',           \n",
      " )                                                                   'vmax_layer[0][0]']          \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 170)                  44030     ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 550270 (2.10 MB)\n",
      "Trainable params: 549374 (2.10 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " img_layer (InputLayer)      [(None, 41, 41, 1)]          0         []                            \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (None, 36, 40, 256)          3328      ['img_layer[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (None, 35, 35, 256)          786688    ['conv2d_26[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (None, 35, 35, 256)          1024      ['conv2d_27[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.relu_4 (TFOpLambda)   (None, 35, 35, 256)          0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooli  (None, 17, 17, 256)          0         ['tf.nn.relu_4[0][0]']        \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (None, 14, 14, 128)          524416    ['max_pooling2d_11[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (None, 14, 14, 128)          512       ['conv2d_28[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.relu_5 (TFOpLambda)   (None, 14, 14, 128)          0         ['batch_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_12 (MaxPooli  (None, 7, 7, 128)            0         ['tf.nn.relu_5[0][0]']        \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (None, 5, 5, 64)             73792     ['max_pooling2d_12[0][0]']    \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (None, 5, 5, 64)             256       ['conv2d_29[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.nn.relu_6 (TFOpLambda)   (None, 5, 5, 64)             0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " max_pooling2d_13 (MaxPooli  (None, 2, 2, 64)             0         ['tf.nn.relu_6[0][0]']        \n",
      " ng2D)                                                                                            \n",
      "                                                                                                  \n",
      " flatten_5 (Flatten)         (None, 256)                  0         ['max_pooling2d_13[0][0]']    \n",
      "                                                                                                  \n",
      " vmax_layer (InputLayer)     [(None, 2)]                  0         []                            \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate  (None, 258)                  0         ['flatten_5[0][0]',           \n",
      " )                                                                   'vmax_layer[0][0]']          \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 170)                  44030     ['concatenate_5[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1434046 (5.47 MB)\n",
      "Trainable params: 1433150 (5.47 MB)\n",
      "Non-trainable params: 896 (3.50 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 200km\n",
    "vmax_input = keras.Input(shape =(2,), name = \"vmax_layer\")\n",
    "img_input = keras.Input(shape =(41, 41, 1), name = \"img_layer\")\n",
    "\n",
    "w = keras.layers.Conv2D(64,8) (img_input)\n",
    "w = keras.layers.Conv2D(64,8)(w)\n",
    "w = keras.layers.Conv2D(64,1)(w)\n",
    "w = keras.layers.BatchNormalization()(w)\n",
    "w = keras.activations.relu(w)\n",
    "w = keras.layers.MaxPool2D(2,2)(w)\n",
    "w = keras.layers.Conv2D(64, 3)(w)\n",
    "w = keras.layers.Conv2D(64, 3)(w)\n",
    "w = keras.layers.Conv2D(256,1)(w)\n",
    "w = keras.layers.BatchNormalization()(w)\n",
    "img_output1 = keras.layers.Flatten()(w)\n",
    "\n",
    "merged_model1 = keras.layers.concatenate([img_output1, vmax_input])\n",
    "output_layer1 = keras.layers.Dense(256)(merged_model1)\n",
    "output_layer1 = keras.layers.Dense(170)(output_layer1)\n",
    "\n",
    "new_model1 = keras.Model(inputs = [img_input, vmax_input], outputs = output_layer1, name = \"model_1\")\n",
    "\n",
    "new_model1.summary()\n",
    "\n",
    "x = keras.layers.Conv2D(256, 8) (img_input)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = keras.layers.MaxPool2D(2,2)(x)\n",
    "x = keras.layers.Conv2D(128,1, activation = 'relu')(x)\n",
    "x = keras.layers.Conv2D(128,5)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = keras.layers.MaxPool2D(2,2)(x)\n",
    "x = keras.layers.Conv2D(64,1, activation = 'relu')(x)\n",
    "x = keras.layers.Conv2D(64,3)(x)\n",
    "x = keras.layers.BatchNormalization()(x)\n",
    "x = keras.activations.relu(x)\n",
    "x = keras.layers.MaxPool2D(2,2)(x)\n",
    "img_output2 = keras.layers.Flatten()(x)\n",
    "\n",
    "merged_model2 = keras.layers.concatenate([img_output2, vmax_input])\n",
    "output_layer2 = keras.layers.Dense(170)(merged_model2)\n",
    "\n",
    "new_model2 = keras.Model(inputs = [img_input, vmax_input], outputs = output_layer2, name = \"model_2\")\n",
    "\n",
    "new_model2.summary()\n",
    "\n",
    "y = keras.layers.Conv2D(256, (6,2))(img_input)\n",
    "y = keras.layers.Conv2D(256, (2,6))(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "y = keras.activations.relu(y)\n",
    "y = keras.layers.MaxPool2D(2,2)(y)\n",
    "y = keras.layers.Conv2D(128,4)(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "y = keras.activations.relu(y)\n",
    "y = keras.layers.MaxPool2D(2,2)(y)\n",
    "y = keras.layers.Conv2D(64,3)(y)\n",
    "y = keras.layers.BatchNormalization()(y)\n",
    "y = keras.activations.relu(y)\n",
    "y = keras.layers.MaxPool2D(2,2)(y)\n",
    "img_output3 = keras.layers.Flatten()(y)\n",
    "\n",
    "merged_model3 = keras.layers.concatenate([img_output3, vmax_input])\n",
    "output_layer3 = keras.layers.Dense(170)(merged_model3)\n",
    "\n",
    "new_model3 = keras.Model(inputs = [img_input, vmax_input], outputs = output_layer3, name = \"model_3\")\n",
    "\n",
    "new_model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "58112/58112 [==============================] - 461s 8ms/step - loss: 5.5928 - mae: 5.5928 - mse: 79.5129\n",
      "Epoch 2/10\n",
      "58112/58112 [==============================] - 460s 8ms/step - loss: 4.5713 - mae: 4.5713 - mse: 43.7893\n",
      "Epoch 3/10\n",
      "58112/58112 [==============================] - 467s 8ms/step - loss: 4.5177 - mae: 4.5177 - mse: 43.2209\n",
      "Epoch 4/10\n",
      "58112/58112 [==============================] - 470s 8ms/step - loss: 4.4877 - mae: 4.4877 - mse: 42.6941\n",
      "Epoch 5/10\n",
      "58112/58112 [==============================] - 474s 8ms/step - loss: 4.4699 - mae: 4.4699 - mse: 42.1806\n",
      "Epoch 6/10\n",
      "58112/58112 [==============================] - 474s 8ms/step - loss: 4.4522 - mae: 4.4522 - mse: 42.1709\n",
      "Epoch 7/10\n",
      "58112/58112 [==============================] - 474s 8ms/step - loss: 4.4463 - mae: 4.4463 - mse: 42.0436\n",
      "Epoch 8/10\n",
      "58112/58112 [==============================] - 475s 8ms/step - loss: 4.4352 - mae: 4.4352 - mse: 41.8772\n",
      "Epoch 9/10\n",
      "58112/58112 [==============================] - 475s 8ms/step - loss: 4.4322 - mae: 4.4322 - mse: 41.6647\n",
      "Epoch 10/10\n",
      "58112/58112 [==============================] - 474s 8ms/step - loss: 4.4173 - mae: 4.4173 - mse: 41.5857\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL1_EPOCHS10_BATCH1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL1_EPOCHS10_BATCH1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 2s 11ms/step - loss: 3.9599 - mae: 3.9599 - mse: 29.9316\n",
      "MAE = 3.959933280944824\n",
      "RMSE = 5.470979247092712\n",
      "135/135 [==============================] - 1s 7ms/step\n",
      "Epoch 1/10\n",
      "29056/29056 [==============================] - 260s 9ms/step - loss: 4.3100 - mae: 4.3100 - mse: 40.3517\n",
      "Epoch 2/10\n",
      "29056/29056 [==============================] - 259s 9ms/step - loss: 4.2977 - mae: 4.2977 - mse: 40.0431\n",
      "Epoch 3/10\n",
      "29056/29056 [==============================] - 259s 9ms/step - loss: 4.2901 - mae: 4.2901 - mse: 39.8170\n",
      "Epoch 4/10\n",
      "29056/29056 [==============================] - 259s 9ms/step - loss: 4.2915 - mae: 4.2915 - mse: 39.8423\n",
      "Epoch 5/10\n",
      "29056/29056 [==============================] - 258s 9ms/step - loss: 4.2857 - mae: 4.2857 - mse: 39.7654\n",
      "Epoch 6/10\n",
      "29056/29056 [==============================] - 256s 9ms/step - loss: 4.2812 - mae: 4.2812 - mse: 39.6229\n",
      "Epoch 7/10\n",
      "29056/29056 [==============================] - 256s 9ms/step - loss: 4.2711 - mae: 4.2711 - mse: 39.5153\n",
      "Epoch 8/10\n",
      "29056/29056 [==============================] - 256s 9ms/step - loss: 4.2655 - mae: 4.2655 - mse: 39.3994\n",
      "Epoch 9/10\n",
      "29056/29056 [==============================] - 256s 9ms/step - loss: 4.2658 - mae: 4.2658 - mse: 39.4644\n",
      "Epoch 10/10\n",
      "29056/29056 [==============================] - 256s 9ms/step - loss: 4.2654 - mae: 4.2654 - mse: 39.4302\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL1_EPOCHS10_BATCH2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL1_EPOCHS10_BATCH2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1s 9ms/step - loss: 3.8620 - mae: 3.8620 - mse: 28.1146\n",
      "MAE = 3.8619744777679443\n",
      "RMSE = 5.302318375429652\n",
      "135/135 [==============================] - 1s 6ms/step\n",
      "Epoch 1/10\n",
      "14528/14528 [==============================] - 143s 10ms/step - loss: 4.1710 - mae: 4.1710 - mse: 38.1621\n",
      "Epoch 2/10\n",
      "14528/14528 [==============================] - 142s 10ms/step - loss: 4.1644 - mae: 4.1644 - mse: 38.0175\n",
      "Epoch 3/10\n",
      "14528/14528 [==============================] - 142s 10ms/step - loss: 4.1611 - mae: 4.1611 - mse: 37.8714\n",
      "Epoch 4/10\n",
      "14528/14528 [==============================] - 142s 10ms/step - loss: 4.1582 - mae: 4.1582 - mse: 37.8866\n",
      "Epoch 5/10\n",
      "14528/14528 [==============================] - 141s 10ms/step - loss: 4.1590 - mae: 4.1590 - mse: 37.7279\n",
      "Epoch 6/10\n",
      "14528/14528 [==============================] - 141s 10ms/step - loss: 4.1390 - mae: 4.1390 - mse: 37.4763\n",
      "Epoch 7/10\n",
      "14528/14528 [==============================] - 141s 10ms/step - loss: 4.1510 - mae: 4.1510 - mse: 37.5956\n",
      "Epoch 8/10\n",
      "14528/14528 [==============================] - 142s 10ms/step - loss: 4.1423 - mae: 4.1423 - mse: 37.6034\n",
      "Epoch 9/10\n",
      "14528/14528 [==============================] - 142s 10ms/step - loss: 4.1374 - mae: 4.1374 - mse: 37.4699\n",
      "Epoch 10/10\n",
      "14528/14528 [==============================] - 141s 10ms/step - loss: 4.1348 - mae: 4.1348 - mse: 37.5415\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL1_EPOCHS10_BATCH4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL1_EPOCHS10_BATCH4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1s 9ms/step - loss: 3.7236 - mae: 3.7236 - mse: 26.5882\n",
      "MAE = 3.7236266136169434\n",
      "RMSE = 5.156374658175889\n",
      "135/135 [==============================] - 1s 6ms/step\n",
      "Epoch 1/10\n",
      "7264/7264 [==============================] - 71s 10ms/step - loss: 4.0614 - mae: 4.0614 - mse: 36.4615\n",
      "Epoch 2/10\n",
      "7264/7264 [==============================] - 69s 10ms/step - loss: 4.0481 - mae: 4.0481 - mse: 36.1709\n",
      "Epoch 3/10\n",
      "7264/7264 [==============================] - 70s 10ms/step - loss: 4.0451 - mae: 4.0451 - mse: 36.2374\n",
      "Epoch 4/10\n",
      "7264/7264 [==============================] - 69s 10ms/step - loss: 4.0417 - mae: 4.0417 - mse: 36.1013\n",
      "Epoch 5/10\n",
      "7264/7264 [==============================] - 69s 10ms/step - loss: 4.0345 - mae: 4.0345 - mse: 36.0467\n",
      "Epoch 6/10\n",
      "7264/7264 [==============================] - 69s 10ms/step - loss: 4.0226 - mae: 4.0226 - mse: 35.9289\n",
      "Epoch 7/10\n",
      "7264/7264 [==============================] - 69s 10ms/step - loss: 4.0276 - mae: 4.0276 - mse: 35.9235\n",
      "Epoch 8/10\n",
      "7264/7264 [==============================] - 69s 9ms/step - loss: 4.0247 - mae: 4.0247 - mse: 35.9145\n",
      "Epoch 9/10\n",
      "7264/7264 [==============================] - 69s 9ms/step - loss: 4.0120 - mae: 4.0120 - mse: 35.7878\n",
      "Epoch 10/10\n",
      "7264/7264 [==============================] - 69s 9ms/step - loss: 4.0081 - mae: 4.0081 - mse: 35.6640\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL1_EPOCHS10_BATCH8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL1_EPOCHS10_BATCH8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1s 9ms/step - loss: 3.6785 - mae: 3.6785 - mse: 25.7796\n",
      "MAE = 3.678530216217041\n",
      "RMSE = 5.077365478055909\n",
      "135/135 [==============================] - 1s 6ms/step\n",
      "Epoch 1/10\n",
      "3632/3632 [==============================] - 39s 10ms/step - loss: 3.9532 - mae: 3.9532 - mse: 34.9766\n",
      "Epoch 2/10\n",
      "3632/3632 [==============================] - 38s 10ms/step - loss: 3.9503 - mae: 3.9503 - mse: 34.8946\n",
      "Epoch 3/10\n",
      "3632/3632 [==============================] - 38s 10ms/step - loss: 3.9475 - mae: 3.9475 - mse: 34.8619\n",
      "Epoch 4/10\n",
      "3632/3632 [==============================] - 38s 10ms/step - loss: 3.9380 - mae: 3.9380 - mse: 34.6521\n",
      "Epoch 5/10\n",
      "3632/3632 [==============================] - 38s 10ms/step - loss: 3.9393 - mae: 3.9393 - mse: 34.7739\n",
      "Epoch 6/10\n",
      "3632/3632 [==============================] - 38s 10ms/step - loss: 3.9269 - mae: 3.9269 - mse: 34.6022\n",
      "Epoch 7/10\n",
      "3632/3632 [==============================] - 38s 10ms/step - loss: 3.9257 - mae: 3.9257 - mse: 34.5823\n",
      "Epoch 8/10\n",
      "3632/3632 [==============================] - 38s 10ms/step - loss: 3.9173 - mae: 3.9173 - mse: 34.4627\n",
      "Epoch 9/10\n",
      "3632/3632 [==============================] - 38s 10ms/step - loss: 3.9174 - mae: 3.9174 - mse: 34.5265\n",
      "Epoch 10/10\n",
      "3632/3632 [==============================] - 38s 10ms/step - loss: 3.9132 - mae: 3.9132 - mse: 34.3612\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL1_EPOCHS10_BATCH16/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL1_EPOCHS10_BATCH16/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1s 9ms/step - loss: 3.6592 - mae: 3.6592 - mse: 25.7242\n",
      "MAE = 3.659181594848633\n",
      "RMSE = 5.071907815221842\n",
      "135/135 [==============================] - 1s 6ms/step\n",
      "Epoch 1/10\n",
      "58112/58112 [==============================] - 416s 7ms/step - loss: 5.1923 - mae: 5.1923 - mse: 64.7489\n",
      "Epoch 2/10\n",
      "58112/58112 [==============================] - 425s 7ms/step - loss: 4.1554 - mae: 4.1554 - mse: 38.4025\n",
      "Epoch 3/10\n",
      "58112/58112 [==============================] - 426s 7ms/step - loss: 4.0783 - mae: 4.0783 - mse: 37.3908\n",
      "Epoch 4/10\n",
      "58112/58112 [==============================] - 431s 7ms/step - loss: 3.9973 - mae: 3.9973 - mse: 36.1618\n",
      "Epoch 5/10\n",
      "58112/58112 [==============================] - 431s 7ms/step - loss: 3.9010 - mae: 3.9010 - mse: 34.6367\n",
      "Epoch 6/10\n",
      "58112/58112 [==============================] - 431s 7ms/step - loss: 3.7647 - mae: 3.7647 - mse: 32.7074\n",
      "Epoch 7/10\n",
      "58112/58112 [==============================] - 430s 7ms/step - loss: 3.5984 - mae: 3.5984 - mse: 30.4279\n",
      "Epoch 8/10\n",
      "58112/58112 [==============================] - 430s 7ms/step - loss: 3.4456 - mae: 3.4456 - mse: 28.3727\n",
      "Epoch 9/10\n",
      "58112/58112 [==============================] - 430s 7ms/step - loss: 3.2865 - mae: 3.2865 - mse: 26.4088\n",
      "Epoch 10/10\n",
      "58112/58112 [==============================] - 430s 7ms/step - loss: 3.1484 - mae: 3.1484 - mse: 24.4708\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL2_EPOCHS10_BATCH1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL2_EPOCHS10_BATCH1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1s 9ms/step - loss: 4.2638 - mae: 4.2638 - mse: 33.6282\n",
      "MAE = 4.263770580291748\n",
      "RMSE = 5.798984030827721\n",
      "135/135 [==============================] - 1s 7ms/step\n",
      "Epoch 1/10\n",
      "29056/29056 [==============================] - 232s 8ms/step - loss: 3.9680 - mae: 3.9680 - mse: 34.8213\n",
      "Epoch 2/10\n",
      "29056/29056 [==============================] - 231s 8ms/step - loss: 3.8526 - mae: 3.8526 - mse: 33.1210\n",
      "Epoch 3/10\n",
      "29056/29056 [==============================] - 231s 8ms/step - loss: 3.7414 - mae: 3.7414 - mse: 31.4407\n",
      "Epoch 4/10\n",
      "29056/29056 [==============================] - 231s 8ms/step - loss: 3.6449 - mae: 3.6449 - mse: 30.1451\n",
      "Epoch 5/10\n",
      "29056/29056 [==============================] - 231s 8ms/step - loss: 3.5644 - mae: 3.5644 - mse: 29.1523\n",
      "Epoch 6/10\n",
      "29056/29056 [==============================] - 233s 8ms/step - loss: 3.4763 - mae: 3.4763 - mse: 27.9663\n",
      "Epoch 7/10\n",
      "29056/29056 [==============================] - 234s 8ms/step - loss: 3.4085 - mae: 3.4085 - mse: 27.0617\n",
      "Epoch 8/10\n",
      "29056/29056 [==============================] - 234s 8ms/step - loss: 3.3192 - mae: 3.3192 - mse: 25.7366\n",
      "Epoch 9/10\n",
      "29056/29056 [==============================] - 234s 8ms/step - loss: 3.2568 - mae: 3.2568 - mse: 24.9224\n",
      "Epoch 10/10\n",
      "29056/29056 [==============================] - 234s 8ms/step - loss: 3.1895 - mae: 3.1895 - mse: 24.1055\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL2_EPOCHS10_BATCH2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL2_EPOCHS10_BATCH2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1s 9ms/step - loss: 3.8370 - mae: 3.8370 - mse: 28.1374\n",
      "MAE = 3.8370258808135986\n",
      "RMSE = 5.304465647399685\n",
      "135/135 [==============================] - 1s 8ms/step\n",
      "Epoch 1/10\n",
      "14528/14528 [==============================] - 132s 9ms/step - loss: 3.0726 - mae: 3.0726 - mse: 22.7224\n",
      "Epoch 2/10\n",
      "14528/14528 [==============================] - 131s 9ms/step - loss: 2.9804 - mae: 2.9804 - mse: 21.5382\n",
      "Epoch 3/10\n",
      "14528/14528 [==============================] - 131s 9ms/step - loss: 2.9069 - mae: 2.9069 - mse: 20.7063\n",
      "Epoch 4/10\n",
      "14528/14528 [==============================] - 131s 9ms/step - loss: 2.8598 - mae: 2.8598 - mse: 20.2217\n",
      "Epoch 5/10\n",
      "14528/14528 [==============================] - 131s 9ms/step - loss: 2.7933 - mae: 2.7933 - mse: 19.4009\n",
      "Epoch 6/10\n",
      "14528/14528 [==============================] - 131s 9ms/step - loss: 2.7423 - mae: 2.7423 - mse: 18.8883\n",
      "Epoch 7/10\n",
      "14528/14528 [==============================] - 131s 9ms/step - loss: 2.6938 - mae: 2.6938 - mse: 18.2297\n",
      "Epoch 8/10\n",
      "14528/14528 [==============================] - 131s 9ms/step - loss: 2.6524 - mae: 2.6524 - mse: 17.8679\n",
      "Epoch 9/10\n",
      "14528/14528 [==============================] - 131s 9ms/step - loss: 2.6026 - mae: 2.6026 - mse: 17.2666\n",
      "Epoch 10/10\n",
      "14528/14528 [==============================] - 131s 9ms/step - loss: 2.5665 - mae: 2.5665 - mse: 16.7504\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL2_EPOCHS10_BATCH4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL2_EPOCHS10_BATCH4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1s 9ms/step - loss: 3.9270 - mae: 3.9270 - mse: 28.8846\n",
      "MAE = 3.9269862174987793\n",
      "RMSE = 5.374442138110563\n",
      "135/135 [==============================] - 1s 8ms/step\n",
      "Epoch 1/10\n",
      "7264/7264 [==============================] - 75s 10ms/step - loss: 2.3867 - mae: 2.3867 - mse: 15.3126\n",
      "Epoch 2/10\n",
      "7264/7264 [==============================] - 72s 10ms/step - loss: 2.3160 - mae: 2.3160 - mse: 14.6344\n",
      "Epoch 3/10\n",
      "7264/7264 [==============================] - 72s 10ms/step - loss: 2.2755 - mae: 2.2755 - mse: 14.2650\n",
      "Epoch 4/10\n",
      "7264/7264 [==============================] - 72s 10ms/step - loss: 2.2326 - mae: 2.2326 - mse: 13.8347\n",
      "Epoch 5/10\n",
      "7264/7264 [==============================] - 72s 10ms/step - loss: 2.1947 - mae: 2.1947 - mse: 13.4704\n",
      "Epoch 6/10\n",
      "7264/7264 [==============================] - 72s 10ms/step - loss: 2.1716 - mae: 2.1716 - mse: 13.0184\n",
      "Epoch 7/10\n",
      "7264/7264 [==============================] - 72s 10ms/step - loss: 2.1387 - mae: 2.1387 - mse: 12.8340\n",
      "Epoch 8/10\n",
      "7264/7264 [==============================] - 72s 10ms/step - loss: 2.1241 - mae: 2.1241 - mse: 12.5915\n",
      "Epoch 9/10\n",
      "7264/7264 [==============================] - 72s 10ms/step - loss: 2.0973 - mae: 2.0973 - mse: 12.3734\n",
      "Epoch 10/10\n",
      "7264/7264 [==============================] - 72s 10ms/step - loss: 2.0703 - mae: 2.0703 - mse: 12.1220\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL2_EPOCHS10_BATCH8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL2_EPOCHS10_BATCH8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1s 10ms/step - loss: 3.9876 - mae: 3.9876 - mse: 29.6159\n",
      "MAE = 3.9876389503479004\n",
      "RMSE = 5.442047672846606\n",
      "135/135 [==============================] - 1s 8ms/step\n",
      "Epoch 1/10\n",
      "3632/3632 [==============================] - 41s 11ms/step - loss: 1.8865 - mae: 1.8865 - mse: 10.9068\n",
      "Epoch 2/10\n",
      "3632/3632 [==============================] - 40s 11ms/step - loss: 1.8306 - mae: 1.8306 - mse: 10.5199\n",
      "Epoch 3/10\n",
      "3632/3632 [==============================] - 40s 11ms/step - loss: 1.7984 - mae: 1.7984 - mse: 10.2390\n",
      "Epoch 4/10\n",
      "3632/3632 [==============================] - 40s 11ms/step - loss: 1.7880 - mae: 1.7880 - mse: 10.0843\n",
      "Epoch 5/10\n",
      "3632/3632 [==============================] - 40s 11ms/step - loss: 1.7616 - mae: 1.7616 - mse: 9.8299\n",
      "Epoch 6/10\n",
      "3632/3632 [==============================] - 40s 11ms/step - loss: 1.7464 - mae: 1.7464 - mse: 9.6878\n",
      "Epoch 7/10\n",
      "3632/3632 [==============================] - 40s 11ms/step - loss: 1.7323 - mae: 1.7323 - mse: 9.5118\n",
      "Epoch 8/10\n",
      "3632/3632 [==============================] - 40s 11ms/step - loss: 1.7114 - mae: 1.7114 - mse: 9.3664\n",
      "Epoch 9/10\n",
      "3632/3632 [==============================] - 40s 11ms/step - loss: 1.6970 - mae: 1.6970 - mse: 9.2256\n",
      "Epoch 10/10\n",
      "3632/3632 [==============================] - 40s 11ms/step - loss: 1.6787 - mae: 1.6787 - mse: 9.0161\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL2_EPOCHS10_BATCH16/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL2_EPOCHS10_BATCH16/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 1s 9ms/step - loss: 4.0328 - mae: 4.0328 - mse: 30.2126\n",
      "MAE = 4.032809257507324\n",
      "RMSE = 5.496601615383573\n",
      "135/135 [==============================] - 1s 8ms/step\n",
      "Epoch 1/10\n",
      "58112/58112 [==============================] - 499s 9ms/step - loss: 5.1624 - mae: 5.1624 - mse: 64.3808\n",
      "Epoch 2/10\n",
      "58112/58112 [==============================] - 507s 9ms/step - loss: 4.0796 - mae: 4.0796 - mse: 36.8172\n",
      "Epoch 3/10\n",
      "58112/58112 [==============================] - 507s 9ms/step - loss: 3.9181 - mae: 3.9181 - mse: 34.5543\n",
      "Epoch 4/10\n",
      "58112/58112 [==============================] - 507s 9ms/step - loss: 3.7052 - mae: 3.7052 - mse: 31.7364\n",
      "Epoch 5/10\n",
      "58112/58112 [==============================] - 507s 9ms/step - loss: 3.4541 - mae: 3.4541 - mse: 28.3054\n",
      "Epoch 6/10\n",
      "58112/58112 [==============================] - 507s 9ms/step - loss: 3.1954 - mae: 3.1954 - mse: 24.9372\n",
      "Epoch 7/10\n",
      "58112/58112 [==============================] - 507s 9ms/step - loss: 2.9785 - mae: 2.9785 - mse: 22.1914\n",
      "Epoch 8/10\n",
      "58112/58112 [==============================] - 507s 9ms/step - loss: 2.7974 - mae: 2.7974 - mse: 19.9431\n",
      "Epoch 9/10\n",
      "58112/58112 [==============================] - 507s 9ms/step - loss: 2.6406 - mae: 2.6406 - mse: 18.0851\n",
      "Epoch 10/10\n",
      "58112/58112 [==============================] - 507s 9ms/step - loss: 2.5022 - mae: 2.5022 - mse: 16.5721\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL3_EPOCHS10_BATCH1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL3_EPOCHS10_BATCH1/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 2s 12ms/step - loss: 5.4228 - mae: 5.4228 - mse: 74.7613\n",
      "MAE = 5.422818660736084\n",
      "RMSE = 8.646459889210304\n",
      "135/135 [==============================] - 2s 11ms/step\n",
      "Epoch 1/10\n",
      "29056/29056 [==============================] - 283s 10ms/step - loss: 3.5440 - mae: 3.5440 - mse: 27.7185\n",
      "Epoch 2/10\n",
      "29056/29056 [==============================] - 282s 10ms/step - loss: 3.3382 - mae: 3.3382 - mse: 25.4230\n",
      "Epoch 3/10\n",
      "29056/29056 [==============================] - 282s 10ms/step - loss: 3.2294 - mae: 3.2294 - mse: 24.0758\n",
      "Epoch 4/10\n",
      "29056/29056 [==============================] - 281s 10ms/step - loss: 3.1424 - mae: 3.1424 - mse: 23.0141\n",
      "Epoch 5/10\n",
      "29056/29056 [==============================] - 283s 10ms/step - loss: 3.0570 - mae: 3.0570 - mse: 22.0065\n",
      "Epoch 6/10\n",
      "29056/29056 [==============================] - 282s 10ms/step - loss: 2.9835 - mae: 2.9835 - mse: 21.1341\n",
      "Epoch 7/10\n",
      "29056/29056 [==============================] - 282s 10ms/step - loss: 2.9177 - mae: 2.9177 - mse: 20.3080\n",
      "Epoch 8/10\n",
      "29056/29056 [==============================] - 282s 10ms/step - loss: 2.8515 - mae: 2.8515 - mse: 19.7867\n",
      "Epoch 9/10\n",
      "29056/29056 [==============================] - 282s 10ms/step - loss: 2.8049 - mae: 2.8049 - mse: 19.1254\n",
      "Epoch 10/10\n",
      "29056/29056 [==============================] - 282s 10ms/step - loss: 2.7539 - mae: 2.7539 - mse: 18.5712\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL3_EPOCHS10_BATCH2/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL3_EPOCHS10_BATCH2/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 2s 12ms/step - loss: 3.8203 - mae: 3.8203 - mse: 27.7231\n",
      "MAE = 3.8203351497650146\n",
      "RMSE = 5.265271455119266\n",
      "135/135 [==============================] - 2s 11ms/step\n",
      "Epoch 1/10\n",
      "14528/14528 [==============================] - 151s 10ms/step - loss: 2.7511 - mae: 2.7511 - mse: 18.7530\n",
      "Epoch 2/10\n",
      "14528/14528 [==============================] - 150s 10ms/step - loss: 2.6671 - mae: 2.6671 - mse: 17.7590\n",
      "Epoch 3/10\n",
      "14528/14528 [==============================] - 150s 10ms/step - loss: 2.5971 - mae: 2.5971 - mse: 16.9560\n",
      "Epoch 4/10\n",
      "14528/14528 [==============================] - 150s 10ms/step - loss: 2.5570 - mae: 2.5570 - mse: 16.5832\n",
      "Epoch 5/10\n",
      "14528/14528 [==============================] - 150s 10ms/step - loss: 2.5059 - mae: 2.5059 - mse: 16.1018\n",
      "Epoch 6/10\n",
      "14528/14528 [==============================] - 150s 10ms/step - loss: 2.4586 - mae: 2.4586 - mse: 15.5626\n",
      "Epoch 7/10\n",
      "14528/14528 [==============================] - 150s 10ms/step - loss: 2.4377 - mae: 2.4377 - mse: 15.3164\n",
      "Epoch 8/10\n",
      "14528/14528 [==============================] - 150s 10ms/step - loss: 2.4010 - mae: 2.4010 - mse: 15.0606\n",
      "Epoch 9/10\n",
      "14528/14528 [==============================] - 150s 10ms/step - loss: 2.3622 - mae: 2.3622 - mse: 14.5913\n",
      "Epoch 10/10\n",
      "14528/14528 [==============================] - 150s 10ms/step - loss: 2.3365 - mae: 2.3365 - mse: 14.3314\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL3_EPOCHS10_BATCH4/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL3_EPOCHS10_BATCH4/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 2s 12ms/step - loss: 3.8087 - mae: 3.8087 - mse: 27.0706\n",
      "MAE = 3.808690309524536\n",
      "RMSE = 5.202940058356861\n",
      "135/135 [==============================] - 2s 11ms/step\n",
      "Epoch 1/10\n",
      "7264/7264 [==============================] - 90s 12ms/step - loss: 2.1949 - mae: 2.1949 - mse: 13.2629\n",
      "Epoch 2/10\n",
      "7264/7264 [==============================] - 90s 12ms/step - loss: 2.1387 - mae: 2.1387 - mse: 12.7762\n",
      "Epoch 3/10\n",
      "7264/7264 [==============================] - 95s 13ms/step - loss: 2.0881 - mae: 2.0881 - mse: 12.3806\n",
      "Epoch 4/10\n",
      "7264/7264 [==============================] - 101s 14ms/step - loss: 2.0683 - mae: 2.0683 - mse: 12.1410\n",
      "Epoch 5/10\n",
      "7264/7264 [==============================] - 106s 15ms/step - loss: 2.0436 - mae: 2.0436 - mse: 11.8237\n",
      "Epoch 6/10\n",
      "7264/7264 [==============================] - 107s 15ms/step - loss: 2.0146 - mae: 2.0146 - mse: 11.5988\n",
      "Epoch 7/10\n",
      "7264/7264 [==============================] - 106s 15ms/step - loss: 1.9936 - mae: 1.9936 - mse: 11.4089\n",
      "Epoch 8/10\n",
      "7264/7264 [==============================] - 104s 14ms/step - loss: 1.9719 - mae: 1.9719 - mse: 11.2093\n",
      "Epoch 9/10\n",
      "7264/7264 [==============================] - 102s 14ms/step - loss: 1.9587 - mae: 1.9587 - mse: 10.9705\n",
      "Epoch 10/10\n",
      "7264/7264 [==============================] - 101s 14ms/step - loss: 1.9423 - mae: 1.9423 - mse: 10.9304\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL3_EPOCHS10_BATCH8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL3_EPOCHS10_BATCH8/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 2s 14ms/step - loss: 3.9242 - mae: 3.9242 - mse: 28.7158\n",
      "MAE = 3.9242281913757324\n",
      "RMSE = 5.358708020404659\n",
      "135/135 [==============================] - 2s 14ms/step\n",
      "Epoch 1/10\n",
      "3632/3632 [==============================] - 87s 24ms/step - loss: 1.7710 - mae: 1.7710 - mse: 9.9223\n",
      "Epoch 2/10\n",
      "3632/3632 [==============================] - 87s 24ms/step - loss: 1.7242 - mae: 1.7242 - mse: 9.6106\n",
      "Epoch 3/10\n",
      "3632/3632 [==============================] - 87s 24ms/step - loss: 1.7009 - mae: 1.7009 - mse: 9.3892\n",
      "Epoch 4/10\n",
      "3632/3632 [==============================] - 87s 24ms/step - loss: 1.6833 - mae: 1.6833 - mse: 9.3157\n",
      "Epoch 5/10\n",
      "3632/3632 [==============================] - 87s 24ms/step - loss: 1.6626 - mae: 1.6626 - mse: 9.0812\n",
      "Epoch 6/10\n",
      "3632/3632 [==============================] - 87s 24ms/step - loss: 1.6496 - mae: 1.6496 - mse: 9.0508\n",
      "Epoch 7/10\n",
      "3632/3632 [==============================] - 87s 24ms/step - loss: 1.6373 - mae: 1.6373 - mse: 8.8658\n",
      "Epoch 8/10\n",
      "3632/3632 [==============================] - 87s 24ms/step - loss: 1.6237 - mae: 1.6237 - mse: 8.7485\n",
      "Epoch 9/10\n",
      "3632/3632 [==============================] - 87s 24ms/step - loss: 1.6176 - mae: 1.6176 - mse: 8.6323\n",
      "Epoch 10/10\n",
      "3632/3632 [==============================] - 87s 24ms/step - loss: 1.6058 - mae: 1.6058 - mse: 8.5186\n",
      "INFO:tensorflow:Assets written to: MODELS/MODEL3_EPOCHS10_BATCH16/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: MODELS/MODEL3_EPOCHS10_BATCH16/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 2s 14ms/step - loss: 3.9659 - mae: 3.9659 - mse: 29.3017\n",
      "MAE = 3.96587872505188\n",
      "RMSE = 5.413103114965755\n",
      "135/135 [==============================] - 2s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "models = {new_model1: '1', new_model2: '2', new_model3: '3'}\n",
    "ep = range(10, 11)\n",
    "batches = [1, 2, 4, 8, 16]\n",
    "for m in models.keys():\n",
    "    for e in ep:\n",
    "        for b in batches:\n",
    "            with tf.device('/GPU:0'):\n",
    "                m.compile(optimizer = 'adam', loss = tf.keras.losses.MeanAbsoluteError(), metrics = ['mae', 'mse'])\n",
    "                m.fit([X_train_img, X_train_vmax], y_train, epochs = e, batch_size = b)\n",
    "                tf.keras.models.save_model(m, f\"MODELS/MODEL{models[m]}_EPOCHS{e}_BATCH{b}\")\n",
    "                res = m.evaluate([X_test_img, X_test_vmax], y_test)\n",
    "                print(\"MAE = \" + str(res[0]))\n",
    "                print(\"RMSE = \" + str((res[2]) ** 0.5))\n",
    "                preds = m.predict([X_test_img, X_test_vmax])\n",
    "                x = np.average(preds, axis = 1)\n",
    "                test['preds'] = x\n",
    "                test.to_csv(f\"OUTPUT/MODEL{models[m]}_RESULTS{e}_{b}.csv\")\n",
    "                tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/sunnyyou/Programs/Real_Time_HAI/HIECNN/IMERG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GIS_ID</th>\n",
       "      <th>VMAX</th>\n",
       "      <th>VMAX_N06</th>\n",
       "      <th>VMAX_N12</th>\n",
       "      <th>CAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL_200001_TD_2000060806</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL_200001_TD_2000060812</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL_200002_TD_2000062312</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL_200002_TD_2000062318</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL_200002_TD_2000062400</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GIS_ID  VMAX  VMAX_N06  VMAX_N12 CAT\n",
       "0  ATL_200001_TD_2000060806    25        25        25  TD\n",
       "1  ATL_200001_TD_2000060812    25        25        25  TD\n",
       "2  ATL_200002_TD_2000062312    30        30        25  TD\n",
       "3  ATL_200002_TD_2000062318    30        30        30  TD\n",
       "4  ATL_200002_TD_2000062400    30        30        30  TD"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_no_resample = pd.read_csv(\"DEV/ALL_TRAIN_DATA.csv\")\n",
    "train_no_resample = train_no_resample[[\"GIS_ID\", \"VMAX\", \"VMAX_N06\", \"VMAX_N12\", \"CAT\"]]\n",
    "train_no_resample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GIS_ID</th>\n",
       "      <th>VMAX</th>\n",
       "      <th>VMAX_N06</th>\n",
       "      <th>VMAX_N12</th>\n",
       "      <th>CAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ATL_201801_TS_2018052812</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>55</td>\n",
       "      <td>TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ATL_201801_TS_2018052818</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>55</td>\n",
       "      <td>TS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ATL_201801_TD_2018052900</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>50</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL_201801_TD_2018052906</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>45</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATL_201801_TD_2018052912</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     GIS_ID  VMAX  VMAX_N06  VMAX_N12 CAT\n",
       "0  ATL_201801_TS_2018052812    50        55        55  TS\n",
       "1  ATL_201801_TS_2018052818    45        50        55  TS\n",
       "2  ATL_201801_TD_2018052900    30        45        50  TD\n",
       "3  ATL_201801_TD_2018052906    30        30        45  TD\n",
       "4  ATL_201801_TD_2018052912    30        30        30  TD"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"DEV/ALL_TEST_DATA.csv\")\n",
    "test = test[[\"GIS_ID\", \"VMAX\", \"VMAX_N06\", \"VMAX_N12\", \"CAT\"]]\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GIS_ID</th>\n",
       "      <th>VMAX</th>\n",
       "      <th>VMAX_N06</th>\n",
       "      <th>VMAX_N12</th>\n",
       "      <th>CAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NWP_201815_TD_2018073012</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SPA_201915_TD_2019021118</td>\n",
       "      <td>30</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NWP_201903_TD_2019031806</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ATL_201810_TD_2018091718</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPA_201814_TD_2018082800</td>\n",
       "      <td>30</td>\n",
       "      <td>35</td>\n",
       "      <td>35</td>\n",
       "      <td>TD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>395</th>\n",
       "      <td>NWP_201915_C4_2019090500</td>\n",
       "      <td>115</td>\n",
       "      <td>105</td>\n",
       "      <td>90</td>\n",
       "      <td>Maj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>396</th>\n",
       "      <td>EPA_201911_C3_2019090400</td>\n",
       "      <td>105</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>Maj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>NWP_201810_C4_2018070712</td>\n",
       "      <td>120</td>\n",
       "      <td>120</td>\n",
       "      <td>115</td>\n",
       "      <td>Maj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>CPA_201810_C3_2018081000</td>\n",
       "      <td>110</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>Maj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>SIO_201807_C3_2018013000</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>110</td>\n",
       "      <td>Maj</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       GIS_ID  VMAX  VMAX_N06  VMAX_N12  CAT\n",
       "0    NWP_201815_TD_2018073012    30        30        30   TD\n",
       "1    SPA_201915_TD_2019021118    30        25        25   TD\n",
       "2    NWP_201903_TD_2019031806    25        25        25   TD\n",
       "3    ATL_201810_TD_2018091718    30        30        30   TD\n",
       "4    CPA_201814_TD_2018082800    30        35        35   TD\n",
       "..                        ...   ...       ...       ...  ...\n",
       "395  NWP_201915_C4_2019090500   115       105        90  Maj\n",
       "396  EPA_201911_C3_2019090400   105       110       110  Maj\n",
       "397  NWP_201810_C4_2018070712   120       120       115  Maj\n",
       "398  CPA_201810_C3_2018081000   110       105       105  Maj\n",
       "399  SIO_201807_C3_2018013000   100       100       110  Maj\n",
       "\n",
       "[400 rows x 5 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_no_resample_TD = train_no_resample[train_no_resample['CAT'] == 'TD']\n",
    "train_no_resample_TD = train_no_resample_TD.sample(100)\n",
    "train_no_resample_TS = train_no_resample[train_no_resample['CAT'] == 'TS']\n",
    "train_no_resample_TS = train_no_resample_TS.sample(100)\n",
    "train_no_resample_Min = train_no_resample[train_no_resample['CAT'] == 'Min']\n",
    "train_no_resample_Min = train_no_resample_Min.sample(100)\n",
    "train_no_resample_Maj = train_no_resample[train_no_resample['CAT'] == 'Maj']\n",
    "train_no_resample_Maj = train_no_resample_Maj.sample(100)\n",
    "shap_train = pd.concat([train_no_resample_TD, train_no_resample_TS, train_no_resample_Min, train_no_resample_Maj])\n",
    "shap_train = shap_train.reset_index(drop = True)\n",
    "shap_train\n",
    "test_TD = test[test['CAT'] == 'TD']\n",
    "test_TS = test[test['CAT'] == 'TS']\n",
    "test_Min = test[test['CAT'] == 'Min']\n",
    "test_Maj = test[test['CAT'] == 'Maj']\n",
    "test_TD = test_TD.sample(100)\n",
    "test_TS = test_TS.sample(100)\n",
    "test_Min = test_Min.sample(100)\n",
    "test_Maj = test_Maj.sample(100)\n",
    "shap_test = pd.concat([test_TD, test_TS, test_Min, test_Maj])\n",
    "shap_test = shap_test.reset_index(drop = True)\n",
    "shap_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_train_img = []\n",
    "shap_train_ships = []\n",
    "shap_train_label = []\n",
    "shap_test_img = []\n",
    "shap_test_ships = []\n",
    "shap_test_label = []\n",
    "for f in range(len(shap_train.GIS_ID)) :\n",
    "    filename = f\"IMERG_CSV/{shap_train.GIS_ID[f]}.csv\"\n",
    "    try:\n",
    "        temp = pd.read_csv(filename, header = None)\n",
    "        if (temp.shape != (121,121)):\n",
    "            continue\n",
    "        temp = temp[40:81]\n",
    "        temp = temp.iloc[:, 40:81]\n",
    "        temp = np.array(temp)\n",
    "        shap_train_img.append(temp)\n",
    "        lab = shap_train.VMAX[f]\n",
    "        shap_train_label.append(lab)\n",
    "        pvmax = np.array([shap_train.VMAX_N06[f], shap_train.VMAX_N12[f]])\n",
    "        shap_train_ships.append(pvmax)\n",
    "    except Exception as e:\n",
    "        pass\n",
    "for f in range(len(shap_test.GIS_ID)):\n",
    "    filename = f\"IMERG_CSV/{shap_test.GIS_ID[f]}.csv\"\n",
    "    try:\n",
    "        temp = pd.read_csv(filename, header = None)\n",
    "        if (temp.shape != (121,121)):\n",
    "            continue\n",
    "        temp = temp[40:81]\n",
    "        temp = temp.iloc[:, 40:81]\n",
    "        temp = np.array(temp)\n",
    "        shap_test_img.append(temp)\n",
    "        lab = shap_test.VMAX[f]\n",
    "        shap_test_label.append(lab)\n",
    "        pvmax = np.array([shap_test.VMAX_N06[f], shap_test.VMAX_N12[f]])\n",
    "        shap_test_ships.append(pvmax)\n",
    "    except Exception as e:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_train_img = np.array(shap_train_img)\n",
    "shap_train_img = shap_train_img.reshape(-1,41,41,1)\n",
    "shap_train_img = shap_train_img.astype('float32')\n",
    "shap_train_ships = np.array(shap_train_ships)\n",
    "shap_train_ships = shap_train_ships.reshape(-1,2)\n",
    "shap_train_label = np.array(shap_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_test_img = np.array(shap_test_img)\n",
    "shap_test_img = shap_test_img.reshape(-1,41,41,1)\n",
    "shap_test_img = shap_test_img.astype('float32')\n",
    "shap_test_ships = np.array(shap_test_ships)\n",
    "shap_test_ships = shap_test_ships.reshape(-1,2)\n",
    "shap_test_label = np.array(shap_test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(shap_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model1.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=['mae', 'mse'])\n",
    "new_model2.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=['mae', 'mse'])\n",
    "new_model3.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.MeanAbsoluteError(),\n",
    "              metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13075/13075 [==============================] - 118s 9ms/step - loss: 2.2197 - mae: 2.2197 - mse: 12.5878 - val_loss: 1.6185 - val_mae: 1.6185 - val_mse: 5.6055\n",
      "135/135 [==============================] - 1s 10ms/step - loss: 4.0457 - mae: 4.0457 - mse: 30.1519\n",
      "MAE = 4.045738220214844\n",
      "RMSE = 5.49107903137744\n",
      "135/135 [==============================] - 1s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "new_model2.fit([X_train_img, X_train_vmax], y_train, epochs=1, batch_size=4, validation_split = 0.1)\n",
    "res = new_model2.evaluate([X_test_img, X_test_vmax], y_test)\n",
    "print(\"MAE = \" + str(res[0]))\n",
    "print(\"RMSE = \" + str((res[2]) ** 0.5))\n",
    "preds = new_model2.predict([X_test_img, X_test_vmax])\n",
    "a = np.average(preds, axis = 1)\n",
    "test['preds'] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your TensorFlow version is newer than 2.4.0 and so graph support has been removed in eager mode and some static graphs may not be supported. See PR #1483 for discussion.\n",
      "`tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/sunnyyou/Programs/Real_Time_HAI/HIECNN/CODE/TC_Estimation.ipynb Cell 24\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sunnyyou/Programs/Real_Time_HAI/HIECNN/CODE/TC_Estimation.ipynb#X31sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m shap\u001b[39m.\u001b[39mexplainers\u001b[39m.\u001b[39m_deep\u001b[39m.\u001b[39mdeep_tf\u001b[39m.\u001b[39mop_handlers[\u001b[39m\"\u001b[39m\u001b[39mFusedBatchNormV3\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39mexplainers\u001b[39m.\u001b[39m_deep\u001b[39m.\u001b[39mdeep_tf\u001b[39m.\u001b[39mlinearity_1d(\u001b[39m0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/sunnyyou/Programs/Real_Time_HAI/HIECNN/CODE/TC_Estimation.ipynb#X31sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m e \u001b[39m=\u001b[39m shap\u001b[39m.\u001b[39mDeepExplainer(new_model2, [shap_train_img, shap_train_ships])\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/sunnyyou/Programs/Real_Time_HAI/HIECNN/CODE/TC_Estimation.ipynb#X31sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m shap_values \u001b[39m=\u001b[39m e\u001b[39m.\u001b[39;49mshap_values([shap_test_img, shap_test_ships])\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/shap/explainers/_deep/__init__.py:125\u001b[0m, in \u001b[0;36mDeepExplainer.shap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mshap_values\u001b[39m(\u001b[39mself\u001b[39m, X, ranked_outputs\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, output_rank_order\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m, check_additivity\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[1;32m     92\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\" Return approximate SHAP values for the model applied to the data given by X.\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \n\u001b[1;32m     94\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39m        were chosen as \"top\".\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 125\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexplainer\u001b[39m.\u001b[39;49mshap_values(X, ranked_outputs, output_rank_order, check_additivity\u001b[39m=\u001b[39;49mcheck_additivity)\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/shap/explainers/_deep/deep_tf.py:312\u001b[0m, in \u001b[0;36mTFDeep.shap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    310\u001b[0m \u001b[39m# run attribution computation graph\u001b[39;00m\n\u001b[1;32m    311\u001b[0m feature_ind \u001b[39m=\u001b[39m model_output_ranks[j,i]\n\u001b[0;32m--> 312\u001b[0m sample_phis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mphi_symbolic(feature_ind), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel_inputs, joint_input)\n\u001b[1;32m    314\u001b[0m \u001b[39m# assign the attributions to the right part of the output arrays\u001b[39;00m\n\u001b[1;32m    315\u001b[0m \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(X)):\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/shap/explainers/_deep/deep_tf.py:363\u001b[0m, in \u001b[0;36mTFDeep.run\u001b[0;34m(self, out, model_inputs, X)\u001b[0m\n\u001b[1;32m    360\u001b[0m         tf_execute\u001b[39m.\u001b[39mrecord_gradient \u001b[39m=\u001b[39m tf_backprop\u001b[39m.\u001b[39mrecord_gradient\n\u001b[1;32m    362\u001b[0m     \u001b[39mreturn\u001b[39;00m final_out\n\u001b[0;32m--> 363\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexecute_with_overridden_gradients(anon)\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/shap/explainers/_deep/deep_tf.py:399\u001b[0m, in \u001b[0;36mTFDeep.execute_with_overridden_gradients\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[39m# define the computation graph for the attribution values using a custom gradient-like computation\u001b[39;00m\n\u001b[1;32m    398\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 399\u001b[0m     out \u001b[39m=\u001b[39m f()\n\u001b[1;32m    400\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    401\u001b[0m     \u001b[39m# reinstate the backpropagatable check\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(tf_gradients_impl, \u001b[39m\"\u001b[39m\u001b[39m_IsBackpropagatable\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/shap/explainers/_deep/deep_tf.py:356\u001b[0m, in \u001b[0;36mTFDeep.run.<locals>.anon\u001b[0;34m()\u001b[0m\n\u001b[1;32m    354\u001b[0m     v \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mconstant(data, dtype\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_inputs[i]\u001b[39m.\u001b[39mdtype)\n\u001b[1;32m    355\u001b[0m     inputs\u001b[39m.\u001b[39mappend(v)\n\u001b[0;32m--> 356\u001b[0m final_out \u001b[39m=\u001b[39m out(inputs)\n\u001b[1;32m    357\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    358\u001b[0m     tf_execute\u001b[39m.\u001b[39mrecord_gradient \u001b[39m=\u001b[39m tf_backprop\u001b[39m.\u001b[39m_record_gradient\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:877\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    875\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 877\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    878\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    879\u001b[0m )\n\u001b[1;32m    880\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    881\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    882\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1487\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1488\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1489\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1490\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1491\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1492\u001b[0m   )\n\u001b[1;32m   1493\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m~/Programs/Real_Time_HAI/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "shap.explainers._deep.deep_tf.op_handlers[\"AddV2\"] = shap.explainers._deep.deep_tf.passthrough\n",
    "shap.explainers._deep.deep_tf.op_handlers[\"FusedBatchNormV3\"] = shap.explainers._deep.deep_tf.linearity_1d(0)\n",
    "e = shap.DeepExplainer(new_model2, [shap_train_img, shap_train_ships])\n",
    "shap_values = e.shap_values([shap_test_img, shap_test_ships])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
